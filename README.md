# Sistema de EjecuciÃ³n Local de Modelos de IA

Sistema para ejecutar modelos de lenguaje grandes (LLMs) localmente y crear arquitecturas de agentes diversos usando Ollama + LangChain.

## ğŸš€ Inicio RÃ¡pido

### 1. Instalar Ollama

```powershell
.\scripts\install_ollama.ps1
```

Cierra y vuelve a abrir PowerShell despuÃ©s de la instalaciÃ³n.

### 2. Descargar Modelos

```powershell
.\scripts\setup_models.ps1
```

Selecciona los modelos que deseas (recomendado: opciÃ³n A para Tier 1).

### 3. Configurar Entorno Python

```powershell
# Crear entorno virtual
python -m venv venv

# Activar entorno
.\venv\Scripts\Activate.ps1

# Instalar dependencias
pip install -r requirements.txt
```

### 4. Probar el Sistema

```powershell
# Chat simple con un modelo
python examples\simple_chat.py

# Sistema multi-agente de investigaciÃ³n
python examples\multi_agent_research.py
```

## ğŸ“ Estructura del Proyecto

```
Agentes-practica/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/              # Motor core del sistema
â”‚   â”‚   â”œâ”€â”€ model_manager.py    # GestiÃ³n de modelos
â”‚   â”‚   â””â”€â”€ ollama_client.py    # Cliente Ollama
â”‚   â”œâ”€â”€ agents/            # Agentes especializados
â”‚   â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”‚   â””â”€â”€ types/
â”‚   â”‚       â”œâ”€â”€ researcher_agent.py
â”‚   â”‚       â”œâ”€â”€ coder_agent.py
â”‚   â”‚       â””â”€â”€ coordinator_agent.py
â”‚   â”œâ”€â”€ orchestration/     # OrquestaciÃ³n multi-agente
â”‚   â”‚   â””â”€â”€ agent_graph.py
â”‚   â”œâ”€â”€ tools/             # Herramientas para agentes
â”‚   â”‚   â””â”€â”€ tool_registry.py
â”‚   â””â”€â”€ monitoring/        # Monitoreo y logging
â”‚       â”œâ”€â”€ resource_monitor.py
â”‚       â””â”€â”€ logger.py
â”œâ”€â”€ config/                # Configuraciones
â”‚   â””â”€â”€ agents.yaml
â”œâ”€â”€ scripts/               # Scripts de instalaciÃ³n
â”‚   â”œâ”€â”€ install_ollama.ps1
â”‚   â””â”€â”€ setup_models.ps1
â”œâ”€â”€ examples/              # Ejemplos de uso
â”œâ”€â”€ tests/                 # Tests automatizados
â”œâ”€â”€ models/                # Modelos descargados (Ollama)
â”œâ”€â”€ docs/                  # DocumentaciÃ³n
â””â”€â”€ logs/                  # Archivos de log
```

## ğŸ¤– Modelos Recomendados

### Tier 1: Uso General (Empezar aquÃ­)
- **Llama 3.2 8B**: Excelente balance, multilingÃ¼e
- **Mistral 7B**: RÃ¡pido y eficiente
- **DeepSeek-R1 8B**: Razonamiento avanzado

### Tier 2: EspecializaciÃ³n
- **Phi-4 14B**: AnÃ¡lisis lÃ³gico intensivo
- **Qwen 2.5 7B**: Coding y multilingÃ¼e
- **Gemma 2 9B**: RÃ¡pido, by Google

### Tier 3: Ultra-Ligeros
- **Phi-3 Mini**: Ultra rÃ¡pido (2.3 GB)
- **TinyLlama**: Extremadamente ligero (637 MB)

## ğŸ› ï¸ Hardware Requerido

- **MÃ­nimo**: 8 GB RAM, CPU moderno
- **Recomendado**: 16+ GB RAM, GPU con 4+ GB VRAM
- **Tu Sistema**: i7-8700, 32GB RAM, GTX 1660 (6GB) âœ… EXCELENTE

## ğŸ“š DocumentaciÃ³n

- [GuÃ­a de Arquitectura](docs/ARCHITECTURE.md)
- [GuÃ­a de Modelos](docs/MODELS_GUIDE.md)
- [Plan de ImplementaciÃ³n](../../brain/e5c370db-365c-47a7-8eda-36721b382bc1/implementation_plan.md)

## ğŸ”§ Comandos Ãštiles de Ollama

```powershell
# Ver modelos instalados
ollama list

# Ejecutar un modelo
ollama run llama3.2

# Eliminar un modelo
ollama rm modelo_name

# Ver info del sistema
ollama show llama3.2
```

## ğŸ“ Licencia

Este proyecto es de cÃ³digo abierto para uso educativo y de desarrollo.
